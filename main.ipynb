{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "cef6c4da",
   "metadata": {},
   "source": [
    "# Intro"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "5b4e9e32",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.0, 0.0, 0.0, 0.0], [0.0, 0.0, 0.0, 0.0], [0.0, 0.0, 0.0, 0.0], [0.0, 0.0, 0.0, 0.0]]\n"
     ]
    }
   ],
   "source": [
    "from tinygrad import Tensor, Context\n",
    "a = Tensor.empty(4,4)\n",
    "b = Tensor.empty(4,4)\n",
    "\n",
    "print((a+b).tolist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "232ffb87",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<Tensor <UOp METAL (4, 4) float (<Ops.ADD: 62>, None)> on METAL with grad None>\n"
     ]
    }
   ],
   "source": [
    "print(a+b)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "78d53ad4",
   "metadata": {},
   "source": [
    "Lazy computation so only computed answer if tolist numpy or realize on tensor are used"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "ac9d4c60",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "#include <metal_stdlib>\n",
      "using namespace metal;\n",
      "kernel void E_16(device float* data0_16, device float* data1_16, device float* data2_16, uint3 gid [[threadgroup_position_in_grid]], uint3 lid [[thread_position_in_threadgroup]]) {\n",
      "  int gidx0 = gid.x; /* 16 */\n",
      "  float val0 = (*(data1_16+gidx0));\n",
      "  float val1 = (*(data2_16+gidx0));\n",
      "  *(data0_16+gidx0) = (val0+val1);\n",
      "}\n",
      "\u001b[32m*** METAL      4\u001b[0m E_\u001b[34m16\u001b[0m\u001b[90m\u001b[0m                                         arg  3 mem  0.00 GB tm      7.25us/     0.02ms (     0.00 GFLOPS    0.0|0.0     GB/s) ['tolist', '__add__', 'empty']\n",
      "[[0.0, 0.0, 0.0, 0.0], [0.0, 0.0, 0.0, 0.0], [0.0, 0.0, 0.0, 0.0], [0.0, 0.0, 0.0, 0.0]]\n",
      "#include <metal_stdlib>\n",
      "using namespace metal;\n",
      "kernel void r_4_4n1(device float* data0_4, device float* data1_16, uint3 gid [[threadgroup_position_in_grid]], uint3 lid [[thread_position_in_threadgroup]]) {\n",
      "  float acc0[1];\n",
      "  int gidx0 = gid.x; /* 4 */\n",
      "  *(acc0+0) = 0.0f;\n",
      "  for (int ridx1001 = 0; ridx1001 < 4; ridx1001++) {\n",
      "    float val0 = (*(data1_16+(gidx0+(ridx1001<<2))));\n",
      "    *(acc0+0) = ((*(acc0+0))+val0);\n",
      "  }\n",
      "  *(data0_4+gidx0) = (*(acc0+0));\n",
      "}\n",
      "\u001b[32m*** METAL      5\u001b[0m r_\u001b[34m4\u001b[0m\u001b[90m_\u001b[0m\u001b[31m4\u001b[0m\u001b[90mn1\u001b[0m                                      arg  2 mem  0.00 GB tm      7.83us/     0.03ms (     0.00 GFLOPS    0.0|0.0     GB/s) ['tolist', 'sum']\n",
      "[0.0, 0.0, 0.0, 0.0]\n"
     ]
    }
   ],
   "source": [
    "with Context(DEBUG=4, NOOPT=True): \n",
    "    a = Tensor.empty(4,4)\n",
    "    b = Tensor.empty(4,4)\n",
    "    print((a+b).tolist())\n",
    "    print((a.sum(0).tolist()))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ca4c8675",
   "metadata": {},
   "source": [
    "UOp is an abstract syntax tree to represent computation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "288a351a",
   "metadata": {},
   "source": [
    "```python\n",
    "class UOp:\n",
    "  op: Ops\n",
    "  dtype: dtypes\n",
    "  src: tuple(UOp)\n",
    "  arg: None\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "07a41997",
   "metadata": {},
   "source": [
    "op field is operation\n",
    "\n",
    "dtype is the data type\n",
    "\n",
    "src is the parents of this node\n",
    "\n",
    "arg is the argument of this node"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "c149e7eb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "UOp(Ops.ADD, dtypes.float, arg=None, src=(\n",
      "  x0:=UOp(Ops.CONST, dtypes.float, arg=1.0, src=()),\n",
      "   x0,))\n"
     ]
    }
   ],
   "source": [
    "from tinygrad.renderer.cstyle import MetalRenderer\n",
    "from tinygrad.uop.ops import UOp, Ops\n",
    "from tinygrad import dtypes\n",
    "\n",
    "const = UOp(Ops.CONST, dtypes.float, arg=1.0)\n",
    "add = UOp(Ops.ADD, dtypes.float, src=(const, const), arg=None)\n",
    "\n",
    "print(add)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "6ad1a42e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "#include <metal_stdlib>\n",
      "using namespace metal;\n",
      "kernel void test(uint3 gid [[threadgroup_position_in_grid]], uint3 lid [[thread_position_in_threadgroup]]) {\n",
      "  float alu0 = (1.0f+1.0f);\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "print(MetalRenderer().render([\n",
    "    const,\n",
    "    add\n",
    "]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "d6f0368b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "#include <metal_stdlib>\n",
      "using namespace metal;\n",
      "kernel void test(uint3 gid [[threadgroup_position_in_grid]], uint3 lid [[thread_position_in_threadgroup]]) {\n",
      "  int gidx0 = gid.x; /* 16 */\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "print(MetalRenderer().render([\n",
    "  UOp(Ops.SPECIAL, dtypes.int, arg=(\"gidx0\", 16))\n",
    "]))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b412b97e",
   "metadata": {},
   "source": [
    "# Pattern matcher"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c5cd5f98",
   "metadata": {},
   "source": [
    "It expresses the entire computation intoa nested tree and then recognizes parts which can be optimized."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "d328037a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "#include <metal_stdlib>\n",
      "using namespace metal;\n",
      "kernel void E_16n1(device float* data0_16, device float* data1_16, uint3 gid [[threadgroup_position_in_grid]], uint3 lid [[thread_position_in_threadgroup]]) {\n",
      "  int gidx0 = gid.x; /* 16 */\n",
      "  float val0 = (*(data1_16+gidx0));\n",
      "  *(data0_16+gidx0) = (val0+1.0f);\n",
      "}\n",
      "\u001b[32m*** METAL      7\u001b[0m E_\u001b[34m16\u001b[0m\u001b[90mn1\u001b[0m                                       arg  2 mem  0.00 GB tm      7.25us/     0.04ms (     0.00 GFLOPS    0.0|0.0     GB/s) ['__add__', 'empty']\n"
     ]
    }
   ],
   "source": [
    "from tinygrad import Tensor\n",
    "\n",
    "with Context(DEBUG=4, NOOPT=True):\n",
    "    a = Tensor.empty(4,4)\n",
    "    b = a + 1\n",
    "\n",
    "    b.realize()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "75b4a95d",
   "metadata": {},
   "source": [
    "This output is unoptimized as one can see it is running not in parallel. The code is generated by looking at the AST which is the tree of UOps."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "55f4ac48",
   "metadata": {},
   "source": [
    "This is the code for how the code is generated from the UOps in the AST.\n",
    "\n",
    "```python\n",
    "patterns = [\n",
    "    (STORE, lambda uop: \"=\"),\n",
    "    (CONST, lambda uop: f\" {uop.arg} \"),\n",
    "    (ADD, lambda uop: f\" + \"),\n",
    "]\n",
    "\n",
    "def render_code(uop):\n",
    "    code = []\n",
    "    for _uop in uop:\n",
    "        if uop.op == pattern[0]:\n",
    "            _code = pattern[1](_uop)\n",
    "            code.append(_code)\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "767b35f4",
   "metadata": {},
   "source": [
    "See above how the tuples store lambda functions to generate the code dynamically based on the UOp specifics like the arg.\n",
    "\n",
    "The lingo:\n",
    "The class PatternMatcher receives the list as init args.\n",
    "Each tuple in list is of class UPat and it has op, dtype, src, args."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e2fda0bf",
   "metadata": {},
   "source": [
    "UOp tree converted to UPat tree.\n",
    "UPat is a minimal abstraction of UOp. \n",
    "\n",
    "See here\n",
    "```python\n",
    "UOp(Ops.STORE, dtypes.void, arg=None, src=(\n",
    "    UOp(Ops.DEFINE_GLOBAL, dtypes.float.ptr(), arg=0, src=()),\n",
    "    ...\n",
    "    UOp(Ops.ADD, dtypes.float, arg=None, src=(\n",
    "      ...\n",
    "    )\n",
    ")\n",
    "\n",
    "# is converted to:\n",
    "\n",
    "UPat(Ops.STORE, name=\"x\", src=(UPat.var(\"define_global\"), UPat.var(\"addition\")), lambda x, define_global, addition: ... )\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "544ab70c",
   "metadata": {},
   "source": [
    "Using the UPat tree, the PatternMatcher can now match the patterns and return corresponding lambda function."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0a7a6d86",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a37c1f07",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
