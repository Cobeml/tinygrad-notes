{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "cef6c4da",
   "metadata": {},
   "source": [
    "# Intro"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "5b4e9e32",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.0, 0.0, 0.0, 0.0], [0.0, 0.0, 0.0, 0.0], [0.0, 0.0, 0.0, 0.0], [0.0, 0.0, 0.0, 0.0]]\n"
     ]
    }
   ],
   "source": [
    "from tinygrad import Tensor, Context\n",
    "a = Tensor.empty(4,4)\n",
    "b = Tensor.empty(4,4)\n",
    "\n",
    "print((a+b).tolist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "232ffb87",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<Tensor <UOp METAL (4, 4) float (<Ops.ADD: 62>, None)> on METAL with grad None>\n"
     ]
    }
   ],
   "source": [
    "print(a+b)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "78d53ad4",
   "metadata": {},
   "source": [
    "Lazy computation so only computed answer if tolist numpy or realize on tensor are used"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "ac9d4c60",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "#include <metal_stdlib>\n",
      "using namespace metal;\n",
      "kernel void E_16(device float* data0_16, device float* data1_16, device float* data2_16, uint3 gid [[threadgroup_position_in_grid]], uint3 lid [[thread_position_in_threadgroup]]) {\n",
      "  int gidx0 = gid.x; /* 16 */\n",
      "  float val0 = (*(data1_16+gidx0));\n",
      "  float val1 = (*(data2_16+gidx0));\n",
      "  *(data0_16+gidx0) = (val0+val1);\n",
      "}\n",
      "\u001b[32m*** METAL      4\u001b[0m E_\u001b[34m16\u001b[0m\u001b[90m\u001b[0m                                         arg  3 mem  0.00 GB tm      7.25us/     0.02ms (     0.00 GFLOPS    0.0|0.0     GB/s) ['tolist', '__add__', 'empty']\n",
      "[[0.0, 0.0, 0.0, 0.0], [0.0, 0.0, 0.0, 0.0], [0.0, 0.0, 0.0, 0.0], [0.0, 0.0, 0.0, 0.0]]\n",
      "#include <metal_stdlib>\n",
      "using namespace metal;\n",
      "kernel void r_4_4n1(device float* data0_4, device float* data1_16, uint3 gid [[threadgroup_position_in_grid]], uint3 lid [[thread_position_in_threadgroup]]) {\n",
      "  float acc0[1];\n",
      "  int gidx0 = gid.x; /* 4 */\n",
      "  *(acc0+0) = 0.0f;\n",
      "  for (int ridx1001 = 0; ridx1001 < 4; ridx1001++) {\n",
      "    float val0 = (*(data1_16+(gidx0+(ridx1001<<2))));\n",
      "    *(acc0+0) = ((*(acc0+0))+val0);\n",
      "  }\n",
      "  *(data0_4+gidx0) = (*(acc0+0));\n",
      "}\n",
      "\u001b[32m*** METAL      5\u001b[0m r_\u001b[34m4\u001b[0m\u001b[90m_\u001b[0m\u001b[31m4\u001b[0m\u001b[90mn1\u001b[0m                                      arg  2 mem  0.00 GB tm      7.83us/     0.03ms (     0.00 GFLOPS    0.0|0.0     GB/s) ['tolist', 'sum']\n",
      "[0.0, 0.0, 0.0, 0.0]\n"
     ]
    }
   ],
   "source": [
    "with Context(DEBUG=4, NOOPT=True): \n",
    "    a = Tensor.empty(4,4)\n",
    "    b = Tensor.empty(4,4)\n",
    "    print((a+b).tolist())\n",
    "    print((a.sum(0).tolist()))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ca4c8675",
   "metadata": {},
   "source": [
    "UOp is an abstract syntax tree to represent computation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "288a351a",
   "metadata": {},
   "source": [
    "```python\n",
    "class UOp:\n",
    "  op: Ops\n",
    "  dtype: dtypes\n",
    "  src: tuple(UOp)\n",
    "  arg: None\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "07a41997",
   "metadata": {},
   "source": [
    "op field is operation\n",
    "\n",
    "dtype is the data type\n",
    "\n",
    "src is the parents of this node\n",
    "\n",
    "arg is the argument of this node"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "c149e7eb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "UOp(Ops.ADD, dtypes.float, arg=None, src=(\n",
      "  x0:=UOp(Ops.CONST, dtypes.float, arg=1.0, src=()),\n",
      "   x0,))\n"
     ]
    }
   ],
   "source": [
    "from tinygrad.renderer.cstyle import MetalRenderer\n",
    "from tinygrad.uop.ops import UOp, Ops\n",
    "from tinygrad import dtypes\n",
    "\n",
    "const = UOp(Ops.CONST, dtypes.float, arg=1.0)\n",
    "add = UOp(Ops.ADD, dtypes.float, src=(const, const), arg=None)\n",
    "\n",
    "print(add)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "6ad1a42e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "#include <metal_stdlib>\n",
      "using namespace metal;\n",
      "kernel void test(uint3 gid [[threadgroup_position_in_grid]], uint3 lid [[thread_position_in_threadgroup]]) {\n",
      "  float alu0 = (1.0f+1.0f);\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "print(MetalRenderer().render([\n",
    "    const,\n",
    "    add\n",
    "]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "d6f0368b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "#include <metal_stdlib>\n",
      "using namespace metal;\n",
      "kernel void test(uint3 gid [[threadgroup_position_in_grid]], uint3 lid [[thread_position_in_threadgroup]]) {\n",
      "  int gidx0 = gid.x; /* 16 */\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "print(MetalRenderer().render([\n",
    "  UOp(Ops.SPECIAL, dtypes.int, arg=(\"gidx0\", 16))\n",
    "]))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b412b97e",
   "metadata": {},
   "source": [
    "# Pattern matcher"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c5cd5f98",
   "metadata": {},
   "source": [
    "It expresses the entire computation intoa nested tree and then recognizes parts which can be optimized."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "d328037a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "#include <metal_stdlib>\n",
      "using namespace metal;\n",
      "kernel void E_16n1(device float* data0_16, device float* data1_16, uint3 gid [[threadgroup_position_in_grid]], uint3 lid [[thread_position_in_threadgroup]]) {\n",
      "  int gidx0 = gid.x; /* 16 */\n",
      "  float val0 = (*(data1_16+gidx0));\n",
      "  *(data0_16+gidx0) = (val0+1.0f);\n",
      "}\n",
      "\u001b[32m*** METAL      7\u001b[0m E_\u001b[34m16\u001b[0m\u001b[90mn1\u001b[0m                                       arg  2 mem  0.00 GB tm      7.25us/     0.04ms (     0.00 GFLOPS    0.0|0.0     GB/s) ['__add__', 'empty']\n"
     ]
    }
   ],
   "source": [
    "from tinygrad import Tensor\n",
    "\n",
    "with Context(DEBUG=4, NOOPT=True):\n",
    "    a = Tensor.empty(4,4)\n",
    "    b = a + 1\n",
    "\n",
    "    b.realize()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "75b4a95d",
   "metadata": {},
   "source": [
    "This output is unoptimized as one can see it is running not in parallel. The code is generated by looking at the AST which is the tree of UOps."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "55f4ac48",
   "metadata": {},
   "source": [
    "This is the code for how the code is generated from the UOps in the AST.\n",
    "\n",
    "```python\n",
    "patterns = [\n",
    "    (STORE, lambda uop: \"=\"),\n",
    "    (CONST, lambda uop: f\" {uop.arg} \"),\n",
    "    (ADD, lambda uop: f\" + \"),\n",
    "]\n",
    "\n",
    "def render_code(uop):\n",
    "    code = []\n",
    "    for _uop in uop:\n",
    "        if uop.op == pattern[0]:\n",
    "            _code = pattern[1](_uop)\n",
    "            code.append(_code)\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "767b35f4",
   "metadata": {},
   "source": [
    "See above how the tuples store lambda functions to generate the code dynamically based on the UOp specifics like the arg.\n",
    "\n",
    "The lingo:\n",
    "The class PatternMatcher receives the list as init args.\n",
    "Each tuple in list is of class UPat and it has op, dtype, src, args."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e2fda0bf",
   "metadata": {},
   "source": [
    "UOp tree converted to UPat tree.\n",
    "UPat is a minimal abstraction of UOp. \n",
    "\n",
    "See here\n",
    "```python\n",
    "UOp(Ops.STORE, dtypes.void, arg=None, src=(\n",
    "    UOp(Ops.DEFINE_GLOBAL, dtypes.float.ptr(), arg=0, src=()),\n",
    "    ...\n",
    "    UOp(Ops.ADD, dtypes.float, arg=None, src=(\n",
    "      ...\n",
    "    )\n",
    ")\n",
    "\n",
    "# is converted to:\n",
    "\n",
    "UPat(Ops.STORE, name=\"x\", src=(UPat.var(\"define_global\"), UPat.var(\"addition\")), lambda x, define_global, addition: ... )\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "544ab70c",
   "metadata": {},
   "source": [
    "Using the UPat tree, the PatternMatcher can now match the patterns and return the code generation once it sees the pattern it is looking for. This pattern can be complicated nested operations."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0a7a6d86",
   "metadata": {},
   "source": [
    "AST can be changed for optimization by changing lambda function: It can return another UOp instead of a string of code.\n",
    "\n",
    "The optimized pattern matching tuple would look different than previous unoptimized. It would look like this: \n",
    "\n",
    "```python\n",
    "  (UPat(Ops.VECTORIZE, name=\"x\"),\n",
    "   lambda ctx,x: f\"{ctx.float4.replace('float4', ctx.render_dtype(x.dtype))}\" + \\\n",
    "    (f\"{{{','.join([ctx[y] for y in x.src])}}}\" if ctx.device == \"CLANG\" else f\"({','.join([ctx[y] for y in x.src])})\")),\n",
    "```\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "51abbef7",
   "metadata": {},
   "source": [
    "For our cases, you could generate new UOp from old one and then from that new one generate code. Would need to chagnge UOp to this for vectorized optimization:\n",
    "\n",
    "```python\n",
    "UOp(Ops.STORE, dtypes.void, arg=None, src=(\n",
    "    UOp(Ops.INDEX, dtypes.float.ptr().vec(4), arg=None, src=(\n",
    "      UOp(Ops.VECTORIZE, dtypes.float.ptr().vec(4), arg=None, src=(\n",
    "        x3:=UOp(Ops.DEFINE_GLOBAL, dtypes.float.ptr(), arg=0, src=()),\n",
    "         x3,\n",
    "         x3,\n",
    "         x3,)),\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a37c1f07",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "#include <metal_stdlib>\n",
      "using namespace metal;\n",
      "kernel void test(device float* data0, uint3 gid [[threadgroup_position_in_grid]], uint3 lid [[thread_position_in_threadgroup]]) {\n",
      "  int gidx0 = gid.x; /* 16 */\n",
      "  *(data0+gidx0) = 1.0f;\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "from tinygrad import dtypes\n",
    "from tinygrad.uop.ops import UOp, Ops\n",
    "from tinygrad.renderer.cstyle import MetalRenderer\n",
    "\n",
    "metal_renderer = MetalRenderer()\n",
    "const = UOp(Ops.CONST, dtypes.float, arg=1.0)\n",
    "define_global = UOp(Ops.DEFINE_GLOBAL, dtypes.float.ptr(), arg=0)\n",
    "special = UOp(Ops.SPECIAL, dtypes.int, arg=('gidx0', 16), src=())\n",
    "added = UOp(Ops.ADD, dtypes.long, arg=None, src=(define_global, special))\n",
    "store = UOp(Ops.STORE, dtypes.void, arg=None, src=(added, const))\n",
    "uops = [const, define_global, special, added, store]\n",
    "\n",
    "rendered = metal_renderer.render(uops)\n",
    "print(rendered)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "8d8940cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tinygrad.uop.ops import PatternMatcher, UPat\n",
    "\n",
    "const_1 = UOp(Ops.CONST, dtypes.float, arg=0.5)\n",
    "const_2 = UOp(Ops.CONST, dtypes.float, arg=0.5)\n",
    "\n",
    "matcher = PatternMatcher([\n",
    "  (UPat(Ops.CONST, dtypes.float, name=\"x\"), lambda ctx, x: UOp(Ops.ADD, dtypes.float, src=(const_1, const_2))),\n",
    "])\n",
    "\n",
    "const = UOp(Ops.CONST, dtypes.float, arg=1.0)\n",
    "const_rewritten = matcher.rewrite(const)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1755177c",
   "metadata": {},
   "source": [
    "Above is a simple example of how a UOp could be rewritten as another UOp using a pattern matcher but to make work with rest of script bc of llinearization requirement, the consts must be added to the `uops` array."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "9982a24f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "#include <metal_stdlib>\n",
      "using namespace metal;\n",
      "kernel void test(device float* data0, uint3 gid [[threadgroup_position_in_grid]], uint3 lid [[thread_position_in_threadgroup]]) {\n",
      "  int gidx0 = gid.x; /* 16 */\n",
      "  *(data0+gidx0) = (0.5f+0.5f);\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "from tinygrad import dtypes\n",
    "from tinygrad.uop.ops import UOp, Ops\n",
    "from tinygrad.renderer.cstyle import MetalRenderer\n",
    "\n",
    "from tinygrad.uop.ops import PatternMatcher, UPat\n",
    "\n",
    "const_1 = UOp(Ops.CONST, dtypes.float, arg=0.5)\n",
    "const_2 = UOp(Ops.CONST, dtypes.float, arg=0.5)\n",
    "\n",
    "matcher = PatternMatcher([\n",
    "  (UPat(Ops.CONST, dtypes.float, name=\"x\"), lambda ctx, x: UOp(Ops.ADD, dtypes.float, src=(const_1, const_2))),\n",
    "])\n",
    "\n",
    "metal_renderer = MetalRenderer()\n",
    "const = UOp(Ops.CONST, dtypes.float, arg=1.0)\n",
    "\n",
    "const_rewritten = matcher.rewrite(const)\n",
    "define_global = UOp(Ops.DEFINE_GLOBAL, dtypes.float.ptr(), arg=0)\n",
    "special = UOp(Ops.SPECIAL, dtypes.int, arg=('gidx0', 16), src=())\n",
    "added = UOp(Ops.ADD, dtypes.long, arg=None, src=(define_global, special))\n",
    "store = UOp(Ops.STORE, dtypes.void, arg=None, src=(added, const_rewritten))\n",
    "uops = [const_1, const_2, const_rewritten, define_global, special, added, store]\n",
    "\n",
    "rendered = metal_renderer.render(uops)\n",
    "print(rendered)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "93f7403c",
   "metadata": {},
   "source": [
    "Why does the meta_renderer.render(uops) takes the uops list as an argument? Why the list? Why not just the new const UOp??? What does it do exactly? Does it need to know the definitions of the other UOps somehow?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1d93f788",
   "metadata": {},
   "source": [
    "# Shape Tracker"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "98e993ba",
   "metadata": {},
   "source": [
    "When matrix is stored linearly in memory need way to keep track of matrix shape!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bfc10fb1",
   "metadata": {},
   "source": [
    "An example is row_number * num_columns + column_number as index"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1a6e1a7d",
   "metadata": {},
   "source": [
    "num_columns here is referred to as stride.\n",
    "\n",
    "Stride is the index number jumped when incrementing the dimensional index (e.g. row or column number)\n",
    "\n",
    "In case of simple 2x2 matrix:\n",
    "1 2\n",
    "3 4\n",
    "stored as: 1 2 3 4\n",
    "the stride of the rows is 2 and stride for the columns is 1."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9978766a",
   "metadata": {},
   "source": [
    "```python\n",
    "View.create(shape=(2,2), strides=(2,1))\n",
    "```\n",
    "\n",
    "Will scale if think of it as 0th and 1st dimensions instead of as row and columns."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b25463bb",
   "metadata": {},
   "source": [
    "Can use this to transpose a matrix by flipping the strides. The actual memory will remain unchanged but how it is interpreted will be different. This reduces computation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "3b4083a8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "UOp(Ops.ADD, dtypes.int, arg=None, src=(\n",
      "  UOp(Ops.ADD, dtypes.int, arg=None, src=(\n",
      "    UOp(Ops.CONST, dtypes.int, arg=0, src=()),\n",
      "    UOp(Ops.MUL, dtypes.int, arg=None, src=(\n",
      "      UOp(Ops.RANGE, dtypes.int, arg=0, src=(\n",
      "        x4:=UOp(Ops.CONST, dtypes.int, arg=2, src=()),)),\n",
      "       x4,)),)),\n",
      "  UOp(Ops.MUL, dtypes.int, arg=None, src=(\n",
      "    UOp(Ops.RANGE, dtypes.int, arg=1, src=(\n",
      "       x4,)),\n",
      "    UOp(Ops.CONST, dtypes.int, arg=1, src=()),)),))\n",
      "((ridx0*2)+ridx1)\n"
     ]
    }
   ],
   "source": [
    "from tinygrad.shape.view import View\n",
    "\n",
    "a = View.create(shape=(2,2), strides=(2,1))\n",
    "\n",
    "idx, valid = a.to_indexed_uops()\n",
    "\n",
    "print(idx)\n",
    "\n",
    "print(idx.render())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c21477ca",
   "metadata": {},
   "source": [
    "This is the same as earlier eqn. For computing memory index. See the bottom line of output for the more concise eqn not written in UOps."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ca23fac5",
   "metadata": {},
   "source": [
    "Can broadcast a vector easily by using a stride of 0 to fill in shape with the same values as in the 0th index of a dimension."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "005f7d64",
   "metadata": {},
   "source": [
    "Also, the shape tracker can be used for matrixes which are stored in memory which is not continuous. But idk how??"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "d175337e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2, 3)\n",
      "(1, 2)\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "a = View.create(shape=(3,2), strides=(2,1))\n",
    "\n",
    "a = a.permute((1,0))\n",
    "print(a.shape)\n",
    "print(a.strides)\n",
    "\n",
    "a = a.reshape((3,2))\n",
    "print(a)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "28960fd8",
   "metadata": {},
   "source": [
    "The returned value is none because a single view can't be reshaped because shape from memory to matrix can no longer be written with just shape and stride: \n",
    "\n",
    "```\n",
    " (3,2)                        (2,3)                    (3,2)\n",
    "0x00 0x01   transpose    0x00 0x02 0x04  reshape     0x00 0x02\n",
    "0x02 0x03 ------------>  0x01 0x03 0x05 ---------->  0x04 0x01\n",
    "0x04 0x05                                            0x03 0x05\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5daa43b0",
   "metadata": {},
   "source": [
    "Shapetracker is an object which can hold multiple views to track shape even in cases such as those."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "30bb8c9a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ShapeTracker(views=(View(shape=(2, 3), strides=(1, 2), offset=0, mask=None, contiguous=False), View(shape=(3, 2), strides=(2, 1), offset=0, mask=None, contiguous=True)))\n"
     ]
    }
   ],
   "source": [
    "from tinygrad.shape.shapetracker import ShapeTracker\n",
    "\n",
    "a = ShapeTracker.from_shape((3,2))\n",
    "a = a.permute((1,0))\n",
    "a = a.reshape((3,2))\n",
    "print(a)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3db235de",
   "metadata": {},
   "source": [
    "Here you can see the views are inputted. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "855f2fc8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(((((ridx0*2)+ridx1)%3)*2)+(((ridx0*2)+ridx1)//3))\n"
     ]
    }
   ],
   "source": [
    "idx, valid = a.to_indexed_uops()\n",
    "print(idx.render())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5ae51802",
   "metadata": {},
   "source": [
    "It gets this eqn by rendering the last view and then project each element onto the first one (does this continually with several views)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b5bc3ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "def views_to_indexed_uops(views: Tuple[View, ...], _idxs:Optional[Tuple[UOp, ...]]=None) -> Tuple[UOp, UOp]:\n",
    "  idx, valid = views[-1].to_indexed_uops(_idxs)\n",
    "  for view in reversed(views[0:-1]):\n",
    "    view = view.minify()\n",
    "    acc, idxs = 1, []\n",
    "    for d in reversed(view.shape):\n",
    "      idxs.append((idx//acc)%d)\n",
    "      acc *= d\n",
    "    idx, valid = view.to_indexed_uops(idxs[::-1], valid)\n",
    "  return idx, valid"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0ad3cd1b",
   "metadata": {},
   "source": [
    "First the expression for the last view is rendered: `row*2+col`, then the relation between this view and previous view is `(expression // acc) % shape` where shape is every shape in the previous view and and the acc is accumulated"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ee81eb5",
   "metadata": {},
   "source": [
    "<img src=\"img/91.png\">"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc6ad144",
   "metadata": {},
   "source": [
    "See the diagram above explaining and breaking down why the formula works. Basically the flattened versions of the matrix before and after reshaping are the same, so if you let their index determining expressions equal to each other you can solve for the indexes in terms of each other and using the logical relation of indexes for transpose and the final flatten, one can determine the memory indexes in terms of the first.\n",
    "\n",
    "I still need to spend more time understanding the actual code though!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "388775c2",
   "metadata": {},
   "source": [
    "# Matmul"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a1fe97cf",
   "metadata": {},
   "source": [
    "Matrix multiplications are either reduction operations where number of dimensions decrease or elementwise operations where the number of dimensions stays the same. \n",
    "\n",
    "Note: Matrixes only get bigger via broadcasting.\n",
    "\n",
    "In tinygrad reduce operations create copys in new memory and elementwise operations change existing memory or shapetracker."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7bffe4a4",
   "metadata": {},
   "source": [
    "All operations can be represented as combinations of these two operations.\n",
    "\n",
    "Examples: \n",
    "\n",
    "```python\n",
    "def mean(self, axis):\n",
    "  summed = self.reduce(ADD, axis)\n",
    "  divided = summed.elementwise(DIVIDE, self.shape[axis])\n",
    "  return divided\n",
    "```\n",
    "\n",
    "```python\n",
    "def max(self, axis):\n",
    "  return self.reduce(MAX, axis)\n",
    "```\n",
    "\n",
    "```python\n",
    "def softmax(self, axis):\n",
    "  _max = self.max(axis)\n",
    "  subtracted = self.elementwise(MINUS, _max)\n",
    "  exp = self.elementwise(EXP)\n",
    "  return exp\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2246b208",
   "metadata": {},
   "source": [
    "How code is generated sort of:\n",
    "\n",
    "```python\n",
    "def elementwise(self, op, other):\n",
    "  return f\"\"\"\n",
    "float res = self {op} other;\n",
    "  \"\"\"\n",
    "```\n",
    "\n",
    "```python\n",
    "def reduce(self, op, axis):\n",
    "  return f\"\"\"\n",
    "float acc = 0;\n",
    "for (int i = 0; i < 16; i++) {\n",
    "  acc = {op}(acc, val);\n",
    "}\n",
    "return acc;\n",
    "\"\"\"\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e6ab2e85",
   "metadata": {},
   "source": [
    "Here is it fr:\n",
    "```python\n",
    "def elementwise(self, op, other):\n",
    "  shape = self.shape\n",
    "  strides = self.strides\n",
    "  index = f\"x * {strides[0]} + y * {strides[1]}\"\n",
    "  return f\"\"\"\n",
    "void elementwise(float* data0, float* data1, float*, data2) {\n",
    "  int x = threadIdx.x;\n",
    "  int y = threadIdx.y;\n",
    "  data0[{index}] = data1[{index}] {op} data2[{index}]; \n",
    "}\n",
    "\"\"\"\n",
    "```\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dda47a4e",
   "metadata": {},
   "source": [
    "Can do a bunch of ShapeTracker changes utilizing broadcasting and transpose then an elementwise multiplication and a sum reduce operation is how you could perform a standard dot product utilizing just"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
